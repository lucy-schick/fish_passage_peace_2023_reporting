## we can switch this to pull from our own system but we will just use simons bcfishpass for now to save time
## simons db will not have the updated pscis names so we we include workflows to see that our new pscis crossings match our old modelled crossings

source('scripts/packages.R')
# source('R/functions.R')

# thinking we better use the remote database since my local version is outdated and not willing to risk a week of time to rebuild (might be fine in a day but never really know till we climb in)
conn <- fpr::fpr_db_conn()

#
##listthe schemas in the database
dbGetQuery(conn,
           "SELECT schema_name
           FROM information_schema.schemata")

# #
# # # ##list tables in a schema
dbGetQuery(conn,
           "SELECT table_name
           FROM information_schema.tables
           WHERE table_schema='bcfishpass'")
  filter(table_name %ilike% 'prec')
# # # # # #
# # # # # # ##list column names in a table
dbGetQuery(conn,
           "SELECT column_name,data_type
           FROM information_schema.columns
           WHERE table_name='map'")


#
# dbGetQuery(conn,
#            "SELECT a.total_lakereservoir_ha
#            FROM bcfishpass.crossings a
#            WHERE stream_crossing_id IN (58159,58161,123446)")
#
# dbGetQuery(conn,
#            "SELECT o.observation_date, o.point_type_code  FROM whse_fish.fiss_fish_obsrvtn_pnt_sp o;") %>%
#   filter(observation_date > '1900-01-01' &
#          observation_date < '2021-02-01') %>%
#   group_by(point_type_code) %>%
#   summarise(min = min(observation_date, na.rm = T),
#             max = max(observation_date, na.rm = T))


#first thing we want to do is match up our pha

pscis_all <- bind_rows(fpr_import_pscis_all())

# n_distinct(pscis_all$aggregated_crossings_id)

dat <- pscis_all %>%
  sf::st_as_sf(coords = c("easting", "northing"),
               crs = 26910, remove = F) %>% ##don't forget to put it in the right crs buds
  sf::st_transform(crs = 3005) ##get the crs same as the layers we want to hit up


# add a unique id - we could just use the reference number
dat$misc_point_id <- seq.int(nrow(dat))

# dbSendQuery(conn, paste0("CREATE SCHEMA IF NOT EXISTS ", "test_hack",";"))
# load to database
sf::st_write(obj = dat, dsn = conn, Id(schema= "working", table = "misc"))


# sf doesn't automagically create a spatial index or a primary key
res <- dbSendQuery(conn, "CREATE INDEX ON working.misc USING GIST (geometry)")
dbClearResult(res)
res <- dbSendQuery(conn, "ALTER TABLE working.misc ADD PRIMARY KEY (misc_point_id)")
dbClearResult(res)

dat_info <- dbGetQuery(conn, "SELECT
  a.misc_point_id,
  b.*,
  ST_Distance(ST_Transform(a.geometry,3005), b.geom) AS distance
FROM
  working.misc AS a
CROSS JOIN LATERAL
  (SELECT *
   FROM bcfishpass.crossings
   ORDER BY
     a.geometry <-> geom
   LIMIT 1) AS b")

##get all the data and save it as an sqlite database as a snapshot of what is happening.  we can always hopefully update it
query <- "SELECT *
   FROM bcfishpass.crossings_vw
   WHERE watershed_group_code IN ('PARS', 'CRKD', 'CARP')"


##import and grab the coordinates - this is already done
bcfishpass<- sf::st_read(conn, query =  query) %>%
  # st_transform(crs = 26911) %>%  #before the coordinates were switched but now they look fine...
  # mutate(
  #        easting = sf::st_coordinates(.)[,1],
  #        northing = sf::st_coordinates(.)[,2]) %>%
  st_drop_geometry() %>%
  mutate(downstream_route_measure = as.integer(downstream_route_measure))
  # dplyr::distinct(.keep_all = T) #needed to do this because there are duplicated outputs


# import the column comments
query <- "select col_description((table_schema||'.'||table_name)::regclass::oid, ordinal_position) as column_comment,
* from information_schema.columns
WHERE table_schema = 'bcfishpass'
and table_name = 'crossings';"

bcfishpass_column_comments <- st_read(conn, query =  query) %>%
  select(column_name, column_comment)

# porphyryr <- st_read(conn, query =
# "SELECT * FROM bcfishpass.crossings
#    WHERE stream_crossing_id = '124487'")

# get the pscis data
query <- "SELECT p.*, wsg.watershed_group_code
   FROM whse_fish.pscis_assessment_svw p
   INNER JOIN whse_basemapping.fwa_watershed_groups_poly wsg
ON ST_Intersects(wsg.geom,p.geom)
WHERE wsg.watershed_group_code IN ('PARS', 'CARP', 'CRKD');"

pscis <- st_read(conn, query =  query)

dbDisconnect(conn = conn)


##join the modelled road data to our pscis submission info
dat_joined <- left_join(
  dat %>% select(-aggregated_crossings_id),
  dat_info %>% select(-utm_zone),
  # select(dat_info,misc_point_id:fcode_label, distance, crossing_id), ##geom keep only the road info and the distance to nearest point from here
  by = "misc_point_id"
)

##DEPRECATED - lets simiplify dat_joined to have a look up -
my_pscis_modelledcrossings_streams_xref <- dat_joined %>%
  select(aggregated_crossings_id, pscis_crossing_id, stream_crossing_id, modelled_crossing_id, site_id, source, distance) %>%
  st_drop_geometry()

# xref my_crossings pscis --------------------------------------------
get_this <- bcdata::bcdc_tidy_resources('pscis-assessments') %>%
  filter(bcdata_available == T)  %>%
  pull(package_id)

dat <- bcdata::bcdc_get_data(get_this)

## xref_pscis_my_crossing_modelled ----------------
xref_pscis_my_crossing_modelled <- dat %>%
  purrr::set_names(nm = tolower(names(.))) %>%
  dplyr::filter(funding_project_number == "peace_2023_Phase1") %>%
  select(external_crossing_reference, stream_crossing_id) %>%
  dplyr::mutate(external_crossing_reference = as.numeric(external_crossing_reference)) %>%
  sf::st_drop_geometry()

# burn to sqlite-------------
##this is how we update our local db.
# mydb <- DBI::dbConnect(RSQLite::SQLite(), "data/bcfishpass.sqlite")
conn <- rws_connect("data/bcfishpass.sqlite")
rws_list_tables(conn)
##archive the last version for now
bcfishpass_archive <- readwritesqlite::rws_read_table("bcfishpass", conn = conn)
rws_drop_table("bcfishpass_archive", conn = conn) ##if it exists get rid of it - might be able to just change exists to T in next line
rws_write(bcfishpass_archive, exists = F, delete = TRUE,
          conn = conn, x_name = paste0("bcfishpass_archive_", format(Sys.time(), "%Y-%m-%d-%H%M")))
rws_drop_table("bcfishpass", conn = conn) ##now drop the table so you can replace it
rws_write(bcfishpass, exists = F, delete = TRUE,
          conn = conn, x_name = "bcfishpass")
# write in the xref
rws_drop_table("xref_pscis_my_crossing_modelled", conn = conn) ##now drop the table so you can replace it
rws_write(xref_pscis_my_crossing_modelled, exists = F, delete = TRUE,
          conn = conn, x_name = "xref_pscis_my_crossing_modelled")
rws_write(pscis, exists = F, delete = TRUE,
          conn = conn, x_name = "pscis")
# add the comments
# bcfishpass_column_comments_archive <- readwritesqlite::rws_read_table("bcfishpass_column_comments", conn = conn)
# rws_write(bcfishpass_column_comments_archive, exists = F, delete = TRUE,
#           conn = conn, x_name = paste0("bcfishpass_column_comments_archive_", format(Sys.time(), "%Y-%m-%d-%H%m")))
rws_drop_table("bcfishpass_column_comments", conn = conn) ##now drop the table so you can replace it
rws_write(bcfishpass_column_comments, exists = F, delete = TRUE,
          conn = conn, x_name = "bcfishpass_column_comments")
rws_list_tables(conn)
rws_disconnect(conn)

##make a dataframe with our crossings that need a match
match_this <- dat_joined %>%
  st_drop_geometry() %>%
  select(pscis_crossing_id, stream_crossing_id, modelled_crossing_id, linear_feature_id, watershed_group_code) %>%
  mutate(reviewer = 'AI',
         notes = "Matched to closest stream model") %>%
  filter(!is.na(pscis_crossing_id) &
           is.na(stream_crossing_id))
# we manually compare results to the xref_pscis_my_crossing_phase2.csv we made and it is correct!

match_this_to_join <- match_this %>%
  select(-stream_crossing_id) %>%
  mutate(linear_feature_id = NA_integer_) %>%
  rename(stream_crossing_id = pscis_crossing_id) %>%
  mutate(across(c(stream_crossing_id:linear_feature_id), as.numeric))


##extra test to see if the match_this hits are already assigned in crossings
test <- bcfishpass %>%
  filter(stream_crossing_id %in% (match_this %>% pull(pscis_crossing_id)))


# ##!!!!!i believe this checks to make sure someone hasn't manually assigned our newly matched crossings....
# ## not sure why it would though so probalby not necessary - old script
# ##need to learn to move from the other fork for now rename and grab from there
# file.copy(from = "C:/scripts/bcfishpass/data/pscis_modelledcrossings_streams_xref.csv",
#             to = "C:/scripts/pscis_modelledcrossings_streams_xref.csv",
#           overwrite = T)
# #
# # ##get the crossing data from bcfishpass
# pscis_modelledcrossings_streams_xref <- readr::read_csv("C:/scripts/pscis_modelledcrossings_streams_xref.csv")
#
#
# ##check to make sure your match_this crossings aren't already assigned somehow
# pscis_modelledcrossings_streams_xref %>%
#   filter(stream_crossing_id %in% (match_this %>% pull(pscis_crossing_id)))

##nope - all good

##grab the bcfishpass spawning and rearing table and put in the database so it can be used to populate the methods and tie to the references table
urlfile="https://raw.githubusercontent.com/smnorris/bcfishpass/main/parameters/example_newgraph/parameters_habitat_thresholds.csv"

bcfishpass_spawn_rear_model <- readr::read_csv(url(urlfile))

# put it in the db
conn <- rws_connect("data/bcfishpass.sqlite")
rws_list_tables(conn)
# archive <- readwritesqlite::rws_read_table("bcfishpass_spawn_rear_model", conn = conn)
# rws_write(archive, exists = F, delete = TRUE,
#           conn = conn, x_name = paste0("bcfishpass_spawn_rear_model_archive_", format(Sys.time(), "%Y-%m-%d-%H%m")))
# rws_drop_table("bcfishpass_spawn_rear_model", conn = conn)
rws_write(bcfishpass_spawn_rear_model, exists = F, delete = TRUE,
          conn = conn, x_name = "bcfishpass_spawn_rear_model")
rws_list_tables(conn)
readwritesqlite::rws_disconnect(conn)


# PSCIS historic info--------------------------------------------------------------------
#to write the background
conn <- DBI::dbConnect(
  RPostgres::Postgres(),
  dbname = "bcfishpass",
  host = "localhost",
  port = "5432",
  user = "postgres",
  password = "postgres"
)

query <- "SELECT p.*, wsg.watershed_group_code FROM whse_fish.pscis_assessment_svw p INNER JOIN whse_basemapping.fwa_watershed_groups_poly wsg ON ST_Intersects(wsg.geom,p.geom)"
pscis_ass <-  sf::st_read(conn, query = query) %>%
  filter(watershed_group_code == 'PARS')


query <- "SELECT p.*, wsg.watershed_group_code FROM whse_fish.pscis_habitat_confirmation_svw p INNER JOIN whse_basemapping.fwa_watershed_groups_poly wsg ON ST_Intersects(wsg.geom,p.geom)"
pscis_con <-  sf::st_read(conn, query = query) %>%
  filter(watershed_group_code == 'PARS')


dbDisconnect(conn = conn)
# put it in the db
conn <- rws_connect("data/bcfishpass.sqlite")
rws_list_tables(conn)
# archive <- readwritesqlite::rws_read_table("bcfishpass_spawn_rear_model", conn = conn)
# rws_write(archive, exists = F, delete = TRUE,
#           conn = conn, x_name = paste0("bcfishpass_spawn_rear_model_archive_", format(Sys.time(), "%Y-%m-%d-%H%m")))
# rws_drop_table("bcfishpass_spawn_rear_model", conn = conn)
rws_write(pscis_ass, exists = F, delete = TRUE,
          conn = conn, x_name = "pscis_historic_phase1")
rws_write(pscis_con, exists = F, delete = TRUE,
          conn = conn, x_name = "pscis_historic_phase2")
rws_write(bcfishpass_spawn_rear_model, exists = F, delete = TRUE,
          conn = conn, x_name = "bcfishpass_spawn_rear_model")
rws_list_tables(conn)
rws_disconnect(conn)
