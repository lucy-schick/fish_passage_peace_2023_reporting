source('scripts/packages.R')

# import a geopackage and rearrange then burn to csv
# relative path to the q project form

# name the project directory we are pulling from
dir_project <- 'sern_peace_fwcp_2023'
# define utm zone of study area
utm <- 10

# # list all the fiss form names in the file
# form_names_l <- list.files(path = paste0('../../gis/',
#                                          dir_project),
#                            # ?glob2rx is a funky little unit
#                            pattern = glob2rx('*fiss_site*.gpkg'),
#                            full.names = T
# ) %>%
#   purrr::map(sf::st_read) %>%
#   bind_rows() %>%
#   # remove the test
#   filter(gazetted_names != 'Robert Hatch')

# # burn raw csv file to backup folder
# form_names_l %>%
#   readr::write_csv(paste0('data/inputs_extracted/mergin_backups/form_fiss_site_raw_',
#                           format(lubridate::now(), "%Y%m%d"), '.csv'), na = '')
#
# # burn amalgamated forms to geopackage
# form_names_l %>%
#   sf::st_write(paste0('data/inputs_extracted/mergin_backups/form_fiss_site_',
#                       format(lubridate::now(), "%Y%m%d"),'.gpkg'), append=FALSE)

# read in cleaned amalgamated fiss form into a list of dataframes using colwise to guess the column types
# if we don't try to guess the col types we have issues later with the bind_rows join
# make sure the file name is the most recent version
form_fiss_site_raw <- sf::st_read(dsn= paste0('../../gis/', dir_project, '/data_field/2023/form_fiss_site_2023.gpkg')) %>%
  st_transform(crs = 26900 + utm) %>%
  poisspatial::ps_sfc_to_coords(X = 'utm_easting', Y = 'utm_northing') %>%
  # round utms to nearest whole numbers, spreadsheet does not allow decimals
  mutate(utm_easting = round(utm_easting),
         utm_northing = round(utm_northing)) %>%
  # add in utm zone of study area
  dplyr::mutate(utm_zone = utm) %>%
  # get a site_id and a location that we can use to make photo directories and tag photos respectively
  tidyr::separate(local_name, into = c('site_id', 'location'), remove = F, extra = "merge") %>%
  #need to rename the photo columns
  dplyr::rename(photo_extra1 = photo_extra_1,
                photo_extra2 = photo_extra_2,
                photo_extra1_tag = photo_extra_1_tag,
                photo_extra2_tag = photo_extra_2_tag,
                photo_typical1 = photo_typical_1,
                photo_typical2 = photo_typical_2)



# see the names of our form
names(form_fiss_site_raw)

# let's get the names of the input template
# there is lots of work to do to pull out all the information we can use so we will start with one small step at a time
# lets just populate the location and site info pages for now and then move on to the other information later
form_raw_names_site <- fpr::fpr_import_hab_con(
  "../dff-2022/data/templates/FDS_Template2023-05-03.xls",
  backup = F,
  row_empty_remove = T) %>%
  # pull out just the site info page for now
  pluck(4) %>%
  # only keep the names of the columns
  names()

# location names
form_raw_names_location <- fpr::fpr_import_hab_con(
  "../dff-2022/data/templates/FDS_Template2023-05-03.xls",
  backup = F,
  row_empty_remove = T) %>%
  # pull out just the site info page for now
  pluck(1) %>%
  # only keep the names of the columns
  names()

# we don't want duplicate column names because it messes with them (renames them both) so we need to get rid of dupes
names_dup <- intersect(form_raw_names_site, form_raw_names_location)

# join the names of our two target tables together without (!) the dupes
form_raw_names_sl <- c(form_raw_names_location,
                       form_raw_names_site[!form_raw_names_site %in% names_dup])


# tidy our populated table to PASTE SPECIAL value only!!! to our template. Might need to be in chunks but so be it
# we also want to know who did the assessments and when to be able to sort the input order and populate the
# habitat_confirmation_priorities spreadsheet so we will add the who and extract the when
# we also want the second comment field and have it appended to the first
# use names(form) to see options
form_site_info_prep <- form_fiss_site_raw %>%
  dplyr::filter(!is.na(date_time_start)) %>%
  dplyr::select(mergin_user,
                date_time_start,
                dplyr::contains('surveyor'),
                dplyr::any_of(form_raw_names_sl),
                comments_2) %>%
  # split out the date and the time - change type of column first
  dplyr::mutate(date_time_start = lubridate::ymd_hms(date_time_start),
                survey_date = lubridate::date(date_time_start),
                time = hms::as_hms(date_time_start)) %>%
  # change "trib" to long version "Tributary"
  mutate(gazetted_names = str_replace_all(gazetted_names, 'Trib ', 'Tributary ')) %>%
  # fill in text columns from spreadsheet that will likely never change
  mutate(waterbody_type = 'stream',
         method_for_channel_width = 'metre tape',
         method_for_wetted_width = 'metre tape',
         method_for_residual_pool_depth = 'metre stick',
         method_for_bankfull_depth = 'metre stick',
         method_for_gradient = 'clinometer',
         method_for_temperature = 'recording meter',
         method_for_conductivity = 'recording meter',
         method_for_p_h = 'pH meter (general)') %>%
  # arrange by surveyor and date/time
  dplyr::arrange(mergin_user, date_time_start) %>%
  #give each row and index so we can filter
  tibble::rowid_to_column()

# identify duplicate sites (that are not NAs) as we don't want to input two of the same
dups <- form_site_info_prep %>%
  filter(!is.na(local_name)) %>%
  group_by(local_name) %>%
  filter(n()>1)

# unhash below to have a look
# view(dups)

# make the loc form
form_fiss_loc <- bind_rows(

  # we need the raw form or we don't have all the right columns
  fpr::fpr_import_hab_con("../dff-2022/data/templates/FDS_Template2023-05-03.xls",
                          backup = F,
                          row_empty_remove = T) %>%
    # pull out just the site info page for now
    pluck(1) %>%
    # need to convert type for some reason (should be guessed already..)
    mutate(survey_date = lubridate::as_date(survey_date)) %>%
    slice(0),

  form_site_info_prep %>%
    # alias local name is not called the same in both sheets so rename
    rename(alias_local_name = local_name,
           gazetted_name = gazetted_names) %>%
    mutate(utm_method = as.character(utm_method)) %>%
    select(rowid,
           dplyr::any_of(form_raw_names_location),
           # add the time to help put the puzzle together after)
           time)
) %>%
  select(rowid, everything())

# make the site form
form_fiss_site <- bind_rows(

  # we need the raw form or we don't have all the right columns
  fpr::fpr_import_hab_con(
    "../dff-2022/data/templates/FDS_Template2023-05-03.xls",
    backup = F,
    row_empty_remove = T) %>%
    # pull out just the site info page for now
    pluck("step_4_stream_site_data") %>%
    slice(0),

  form_site_info_prep %>%
    mutate(morphology = as.character(morphology),
           utm_method = as.character(utm_method)) %>%
    select(rowid,
           dplyr::any_of(form_raw_names_site),
           # add the time to help put the puzzle together after)
           survey_date,
           time)
) %>%
  # add time to end of comments, there are no comments in the comments_2 column so no need to combine
  dplyr::mutate(comments = paste0(comments, ' ', time)) %>%
  select(rowid, everything())

# burn to file
form_fiss_loc %>%
  readr::write_csv(paste0(
    'data/inputs_extracted/form_fiss_loc_tidy_',
    format(lubridate::now(), "%Y%m%d"),
    '.csv'),
    na = '')

form_fiss_site %>%
  readr::write_csv(paste0(
    'data/inputs_extracted/form_fiss_site_tidy_',
    format(lubridate::now(), "%Y%m%d"),
    '.csv'),
    na = '')




